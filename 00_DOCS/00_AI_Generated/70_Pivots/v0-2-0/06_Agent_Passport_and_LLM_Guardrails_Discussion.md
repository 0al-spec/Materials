# Agent Passport и LLM Guardrails

## Вопрос

> https://habr.com/ru/articles/936156/

Каким образом и надо ли включать в Agent Passport описание защиты встроенной в агента LLM с помощью Guardrails? Лично я скептически настроен, считаю, что этот вопрос не входит в scope явлений, так как относится к внутренней сущности LLM, но может я и неправ.

## Ответ

Вы абсолютно правы в своем скептицизме. Включение детального описания внутренних механизмов защиты LLM, таких как Guardrails, напрямую не входит в текущую концепцию и scope Agent Passport.
Ваше предположение верно: это относится к внутренней реализации агента, в то время как паспорт фокусируется на внешнем, верифицируемом и принудительно исполняемом "контракте" агента с окружающим миром.

Вот несколько аргументов из самого документа, подтверждающих эту точку зрения:

### Почему прямое указание Guardrails не подходит?

 * [cite_start]Уровень абстракции: Agent Passport — это аналог человеческого паспорта. [cite_start]Он подтверждает личность, заявленные "права" (возможности) и, что самое важное, ограничения (политики безопасности), которые могут быть принудительно исполнены извне. Паспорт не описывает внутренние убеждения или моральные принципы человека; точно так же он не должен описывать внутреннюю архитектуру защиты LLM.
 * [cite_start]LLM-агностицизм: Спецификация целенаправленно создана так, чтобы не быть привязанной к конкретной LLM. Включение специфической технологии, как Guardrails, нарушило бы этот принцип, поскольку у разных моделей (GPT, Llama, Gemini) могут быть свои, совершенно иные механизмы внутреннего контроля.
 * [cite_start]Принудительное исполнение (Enforcement): Политики безопасности, описанные в паспорте (seccomp, chroot, сетевые ограничения), предназначены для принудительного применения со стороны внешней исполняющей среды (runtime), такой как agentifyd. Runtime может заблокировать системный вызов или сетевое соединение, но он не может напрямую контролировать внутреннюю логику работы Guardrails в LLM.

### Альтернативный подход: как можно учесть аспект безопасности LLM?

Хотя указание конкретной реализации (Guardrails) нецелесообразно, можно отразить намерение обеспечить безопасное поведение агента на более высоком уровне. [cite_start]Это соответствует принципу расширяемости (Extensibility) спецификации.

Это можно сделать через декларацию поведенческих политик в разделе securityPolicies или в новом разделе.

#### Пример:

Вместо того чтобы писать:

```
# Неправильный подход
securityPolicies:
  llmInternal:
    guardrails: "enabled"
    version: "2.1"
```

Можно было бы добавить более абстрактное поле:

```
# Возможный правильный подход
securityPolicies:
  contentPolicy:
    level: "no-hate-speech-no-pii"
    # Описание политики: "Агент не должен генерировать враждебные высказывания
    # или обрабатывать персональные данные (PII) в открытом виде".
``` 

В такой модели:

 * Разработчик агента заявляет, что его агент соответствует определенной политике контента.
 * [cite_start]Удостоверяющий центр (Issuing Authority) при выпуске паспорта должен будет проверить (например, через тестирование или аудит кода), что внутренние механизмы агента — будь то Guardrails, специальное дообучение или что-то еще — действительно обеспечивают соблюдение этой заявленной политики.
 * Runtime может использовать эту информацию для дополнительного мониторинга или для принятия решений о доверии к агенту.

**Таким образом, вы сохраняете абстракцию и LLM-агностицизм, но при этом делаете безопасность поведения агента частью его верифицируемой “личности”.**
